{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this kernel, we have implemented a multi-class decision tree algorithm to classify diseases using the annotation files. These contain information on the number of crackles and wheezes in each recording. \n",
    "\n",
    "We first start with rearding the patient diagnosis and demographic info files."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Reading the data\n",
    "df = pd.read_csv('la2_rankIIIonly_extended.csv')\n",
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11895 entries, 0 to 11894\n",
      "Data columns (total 48 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   gameId                       11895 non-null  int64 \n",
      " 1   region                       11895 non-null  object\n",
      " 2   summonerName                 11895 non-null  object\n",
      " 3   tier                         11895 non-null  object\n",
      " 4   rank                         11895 non-null  object\n",
      " 5   tierRank                     11895 non-null  object\n",
      " 6   wins                         11895 non-null  int64 \n",
      " 7   losses                       11895 non-null  int64 \n",
      " 8   win                          11895 non-null  bool  \n",
      " 9   lane                         11895 non-null  object\n",
      " 10  role                         11895 non-null  object\n",
      " 11  championId                   11895 non-null  int64 \n",
      " 12  spell1Id                     11895 non-null  int64 \n",
      " 13  spell2Id                     11895 non-null  int64 \n",
      " 14  kills                        11895 non-null  int64 \n",
      " 15  deaths                       11895 non-null  int64 \n",
      " 16  assists                      11895 non-null  int64 \n",
      " 17  largestKillingSpree          11895 non-null  int64 \n",
      " 18  largestMultiKill             11895 non-null  int64 \n",
      " 19  killingSprees                11895 non-null  int64 \n",
      " 20  longestTimeSpentLiving       11895 non-null  int64 \n",
      " 21  doubleKills                  11895 non-null  int64 \n",
      " 22  tripleKills                  11895 non-null  int64 \n",
      " 23  quadraKills                  11895 non-null  int64 \n",
      " 24  pentaKills                   11895 non-null  int64 \n",
      " 25  totalDamageDealt             11895 non-null  int64 \n",
      " 26  totalDamageDealtToChampions  11895 non-null  int64 \n",
      " 27  totalHeal                    11895 non-null  int64 \n",
      " 28  totalUnitsHealed             11895 non-null  int64 \n",
      " 29  damageDealtToObjectives      11895 non-null  int64 \n",
      " 30  timeCCingOthers              11895 non-null  int64 \n",
      " 31  totalDamageTaken             11895 non-null  int64 \n",
      " 32  totalMinionsKilled           11895 non-null  int64 \n",
      " 33  goldEarned                   11895 non-null  int64 \n",
      " 34  goldSpent                    11895 non-null  int64 \n",
      " 35  visionScore                  11895 non-null  int64 \n",
      " 36  team-firstBlood              11895 non-null  bool  \n",
      " 37  team-firstTower              11895 non-null  bool  \n",
      " 38  team-firstInhibitor          11895 non-null  bool  \n",
      " 39  team-firstBaron              11895 non-null  bool  \n",
      " 40  team-firstDragon             11895 non-null  bool  \n",
      " 41  team-firstRiftHerald         11895 non-null  bool  \n",
      " 42  team-towerKills              11895 non-null  int64 \n",
      " 43  team-inhibitorKills          11895 non-null  int64 \n",
      " 44  team-baronKills              11895 non-null  int64 \n",
      " 45  team-dragonKills             11895 non-null  int64 \n",
      " 46  team-vilemawKills            11895 non-null  int64 \n",
      " 47  team-riftHeraldKills         11895 non-null  int64 \n",
      "dtypes: bool(7), int64(34), object(7)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Handling Missing Data for Decision Tree Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Review missing data\n",
    "print(df.isnull().sum())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gameId                         0\n",
      "region                         0\n",
      "summonerName                   0\n",
      "tier                           0\n",
      "rank                           0\n",
      "tierRank                       0\n",
      "wins                           0\n",
      "losses                         0\n",
      "win                            0\n",
      "lane                           0\n",
      "role                           0\n",
      "championId                     0\n",
      "spell1Id                       0\n",
      "spell2Id                       0\n",
      "kills                          0\n",
      "deaths                         0\n",
      "assists                        0\n",
      "largestKillingSpree            0\n",
      "largestMultiKill               0\n",
      "killingSprees                  0\n",
      "longestTimeSpentLiving         0\n",
      "doubleKills                    0\n",
      "tripleKills                    0\n",
      "quadraKills                    0\n",
      "pentaKills                     0\n",
      "totalDamageDealt               0\n",
      "totalDamageDealtToChampions    0\n",
      "totalHeal                      0\n",
      "totalUnitsHealed               0\n",
      "damageDealtToObjectives        0\n",
      "timeCCingOthers                0\n",
      "totalDamageTaken               0\n",
      "totalMinionsKilled             0\n",
      "goldEarned                     0\n",
      "goldSpent                      0\n",
      "visionScore                    0\n",
      "team-firstBlood                0\n",
      "team-firstTower                0\n",
      "team-firstInhibitor            0\n",
      "team-firstBaron                0\n",
      "team-firstDragon               0\n",
      "team-firstRiftHerald           0\n",
      "team-towerKills                0\n",
      "team-inhibitorKills            0\n",
      "team-baronKills                0\n",
      "team-dragonKills               0\n",
      "team-vilemawKills              0\n",
      "team-riftHeraldKills           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Eliminate rows with missing values\n",
    "df.dropna(inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-class Decision Tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(df.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       gameId region summonerName  tier rank  tierRank  wins  losses    win  \\\n",
      "0  1008260800    la2  starboy2003  IRON  III  IRON-III     3       8   True   \n",
      "1  1008218594    la2  starboy2003  IRON  III  IRON-III     3       8  False   \n",
      "2  1007865682    la2  starboy2003  IRON  III  IRON-III     3       8  False   \n",
      "3  1007660020    la2  starboy2003  IRON  III  IRON-III     3       8  False   \n",
      "4  1007272625    la2  starboy2003  IRON  III  IRON-III     3       8  False   \n",
      "\n",
      "     lane  ... team-firstInhibitor  team-firstBaron  team-firstDragon  \\\n",
      "0  BOTTOM  ...                True             True             False   \n",
      "1  BOTTOM  ...               False            False              True   \n",
      "2  BOTTOM  ...               False            False              True   \n",
      "3  BOTTOM  ...               False            False             False   \n",
      "4  BOTTOM  ...               False            False             False   \n",
      "\n",
      "   team-firstRiftHerald  team-towerKills  team-inhibitorKills  \\\n",
      "0                  True               11                    3   \n",
      "1                  True                2                    0   \n",
      "2                 False                1                    0   \n",
      "3                  True                5                    0   \n",
      "4                  True                7                    0   \n",
      "\n",
      "   team-baronKills  team-dragonKills  team-vilemawKills  team-riftHeraldKills  \n",
      "0                2                 2                  0                     2  \n",
      "1                0                 1                  0                     1  \n",
      "2                0                 1                  0                     0  \n",
      "3                0                 0                  0                     2  \n",
      "4                0                 3                  0                     2  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X = df.drop(['tier', 'rank', 'tierRank', 'region', 'summonerName', 'lane', 'role'], axis=1).values\n",
    "X_columns = df.drop(['tier', 'rank', 'tierRank', 'region', 'summonerName', 'lane', 'role'], axis=1).columns\n",
    "y = df[['tier']].to_numpy().ravel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# encoding categorical data e.g. tier as a dummy variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:,1] = labelencoder_X.fit_transform(X[:,1])\n",
    "\n",
    "# encoding categorical data e.g. tier as a dummy variable\n",
    "y,class_names = pd.factorize(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y, random_state = 42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Fitting Classifier to the Training Set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion='gini', max_depth=27, random_state=42)\n",
    "classifier.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=27, random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Model performance on training set\n",
    "y_pred_train =classifier.predict(X_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred_train)\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "cm=confusion_matrix(y_train,y_pred_train)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "print(classification_report(y_train, y_pred_train, target_names=class_names))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 1.00\n",
      "Confusion Matrix: \n",
      " [[1491    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0]\n",
      " [   0    0 1483    0    0    0]\n",
      " [   0    0    0 1478    0    0]\n",
      " [   0    0    0    0 1484    0]\n",
      " [   0    0    0    0    0 1485]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        IRON       1.00      1.00      1.00      1491\n",
      "      BRONZE       1.00      1.00      1.00      1500\n",
      "      SILVER       1.00      1.00      1.00      1483\n",
      "        GOLD       1.00      1.00      1.00      1478\n",
      "    PLATINUM       1.00      1.00      1.00      1484\n",
      "     DIAMOND       1.00      1.00      1.00      1485\n",
      "\n",
      "    accuracy                           1.00      8921\n",
      "   macro avg       1.00      1.00      1.00      8921\n",
      "weighted avg       1.00      1.00      1.00      8921\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Predicting the test results\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "# Classification results on test set\n",
    "from sklearn import metrics\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.79\n",
      "Confusion Matrix: \n",
      " [[410  48  25   8   3   3]\n",
      " [ 39 389  35   9  20   8]\n",
      " [ 16  37 395  21  17   9]\n",
      " [ 16  22  16 381  25  32]\n",
      " [ 11  24  18  22 385  35]\n",
      " [  1   9  15  20  52 398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        IRON       0.83      0.82      0.83       497\n",
      "      BRONZE       0.74      0.78      0.76       500\n",
      "      SILVER       0.78      0.80      0.79       495\n",
      "        GOLD       0.83      0.77      0.80       492\n",
      "    PLATINUM       0.77      0.78      0.77       495\n",
      "     DIAMOND       0.82      0.80      0.81       495\n",
      "\n",
      "    accuracy                           0.79      2974\n",
      "   macro avg       0.79      0.79      0.79      2974\n",
      "weighted avg       0.79      0.79      0.79      2974\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Visualize the tree by graphiz\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Users/matia/anaconda3/Library/bin/graphviz/'\n",
    "feature_names = X_columns\n",
    "dot_data = tree.export_graphviz(classifier, out_file=None, filled=True, rounded = True, feature_names=feature_names, class_names=class_names)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-aa04854d4d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize the tree by graphiz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PATH\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathsep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'C:/Users/matia/anaconda3/Library/bin/graphviz/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a3c66e335c957f5dc4473268fe59f59400734c4901a7cb7ec2dfb96befc7497"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('mineria_env': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}