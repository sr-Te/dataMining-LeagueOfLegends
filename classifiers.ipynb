{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Import libraries\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from matplotlib.colors import ListedColormap\r\n",
    "import time\r\n",
    "\r\n",
    "# for splitting data into training and testing\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "# standardize features removing the mean and scaling to unit variance\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "# multilayer perceptron classifier\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "\r\n",
    "# K nearest neighbors classifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "# Support vector machine, C-support vector classifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "# Gaussian process classifier\r\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\r\n",
    "\r\n",
    "# radial basis function kernel (squared exponential kernel)\r\n",
    "from sklearn.gaussian_process.kernels import RBF\r\n",
    "\r\n",
    "# Decision tree classifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "# Ensemble classifiers: Random forest and AdaBoost\r\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\r\n",
    "\r\n",
    "# Naive Bayes classifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "\r\n",
    "# Quadratic Discriminant Analysis classifier\r\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\r\n",
    "\r\n",
    "from sklearn import metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Reading the data\r\n",
    "# df = pd.read_csv('la2_rankIIIonly_extended.csv')\r\n",
    "df = pd.read_csv('csv/la2_50matchs.csv')\r\n",
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118292 entries, 0 to 118291\n",
      "Data columns (total 48 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   gameId                       118292 non-null  int64 \n",
      " 1   region                       118292 non-null  object\n",
      " 2   summonerName                 118292 non-null  object\n",
      " 3   tier                         118292 non-null  object\n",
      " 4   rank                         118292 non-null  object\n",
      " 5   tierRank                     118292 non-null  object\n",
      " 6   wins                         118292 non-null  int64 \n",
      " 7   losses                       118292 non-null  int64 \n",
      " 8   win                          118292 non-null  bool  \n",
      " 9   lane                         118292 non-null  object\n",
      " 10  role                         118292 non-null  object\n",
      " 11  championId                   118292 non-null  int64 \n",
      " 12  spell1Id                     118292 non-null  int64 \n",
      " 13  spell2Id                     118292 non-null  int64 \n",
      " 14  kills                        118292 non-null  int64 \n",
      " 15  deaths                       118292 non-null  int64 \n",
      " 16  assists                      118292 non-null  int64 \n",
      " 17  largestKillingSpree          118292 non-null  int64 \n",
      " 18  largestMultiKill             118292 non-null  int64 \n",
      " 19  killingSprees                118292 non-null  int64 \n",
      " 20  longestTimeSpentLiving       118292 non-null  int64 \n",
      " 21  doubleKills                  118292 non-null  int64 \n",
      " 22  tripleKills                  118292 non-null  int64 \n",
      " 23  quadraKills                  118292 non-null  int64 \n",
      " 24  pentaKills                   118292 non-null  int64 \n",
      " 25  totalDamageDealt             118292 non-null  int64 \n",
      " 26  totalDamageDealtToChampions  118292 non-null  int64 \n",
      " 27  totalHeal                    118292 non-null  int64 \n",
      " 28  totalUnitsHealed             118292 non-null  int64 \n",
      " 29  damageDealtToObjectives      118292 non-null  int64 \n",
      " 30  timeCCingOthers              118292 non-null  int64 \n",
      " 31  totalDamageTaken             118292 non-null  int64 \n",
      " 32  totalMinionsKilled           118292 non-null  int64 \n",
      " 33  goldEarned                   118292 non-null  int64 \n",
      " 34  goldSpent                    118292 non-null  int64 \n",
      " 35  visionScore                  118292 non-null  int64 \n",
      " 36  team-firstBlood              118292 non-null  bool  \n",
      " 37  team-firstTower              118292 non-null  bool  \n",
      " 38  team-firstInhibitor          118292 non-null  bool  \n",
      " 39  team-firstBaron              118292 non-null  bool  \n",
      " 40  team-firstDragon             118292 non-null  bool  \n",
      " 41  team-firstRiftHerald         118292 non-null  bool  \n",
      " 42  team-towerKills              118292 non-null  int64 \n",
      " 43  team-inhibitorKills          118292 non-null  int64 \n",
      " 44  team-baronKills              118292 non-null  int64 \n",
      " 45  team-dragonKills             118292 non-null  int64 \n",
      " 46  team-vilemawKills            118292 non-null  int64 \n",
      " 47  team-riftHeraldKills         118292 non-null  int64 \n",
      "dtypes: bool(7), int64(34), object(7)\n",
      "memory usage: 37.8+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Review missing data\r\n",
    "print(df.isnull().sum())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gameId                         0\n",
      "region                         0\n",
      "summonerName                   0\n",
      "tier                           0\n",
      "rank                           0\n",
      "tierRank                       0\n",
      "wins                           0\n",
      "losses                         0\n",
      "win                            0\n",
      "lane                           0\n",
      "role                           0\n",
      "championId                     0\n",
      "spell1Id                       0\n",
      "spell2Id                       0\n",
      "kills                          0\n",
      "deaths                         0\n",
      "assists                        0\n",
      "largestKillingSpree            0\n",
      "largestMultiKill               0\n",
      "killingSprees                  0\n",
      "longestTimeSpentLiving         0\n",
      "doubleKills                    0\n",
      "tripleKills                    0\n",
      "quadraKills                    0\n",
      "pentaKills                     0\n",
      "totalDamageDealt               0\n",
      "totalDamageDealtToChampions    0\n",
      "totalHeal                      0\n",
      "totalUnitsHealed               0\n",
      "damageDealtToObjectives        0\n",
      "timeCCingOthers                0\n",
      "totalDamageTaken               0\n",
      "totalMinionsKilled             0\n",
      "goldEarned                     0\n",
      "goldSpent                      0\n",
      "visionScore                    0\n",
      "team-firstBlood                0\n",
      "team-firstTower                0\n",
      "team-firstInhibitor            0\n",
      "team-firstBaron                0\n",
      "team-firstDragon               0\n",
      "team-firstRiftHerald           0\n",
      "team-towerKills                0\n",
      "team-inhibitorKills            0\n",
      "team-baronKills                0\n",
      "team-dragonKills               0\n",
      "team-vilemawKills              0\n",
      "team-riftHeraldKills           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Eliminate rows with missing values\r\n",
    "df.dropna(inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "X = df.drop(['tier', 'rank', 'tierRank', 'region', 'summonerName', 'lane', 'role'], axis=1).values\r\n",
    "X_columns = df.drop(['tier', 'rank', 'tierRank', 'region', 'summonerName', 'lane', 'role'], axis=1).columns\r\n",
    "y = df[['tier']].to_numpy().ravel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# encoding categorical data e.g. tier as a dummy variable\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "labelencoder_X = LabelEncoder()\r\n",
    "X[:,1] = labelencoder_X.fit_transform(X[:,1])\r\n",
    "\r\n",
    "# encoding categorical data e.g. tier as a dummy variable\r\n",
    "y,class_names = pd.factorize(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Splitting the dataset into the Training set and Test set\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y, random_state = 42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Function to pretty print the confusion matrix\r\n",
    "\r\n",
    "import itertools\r\n",
    "\r\n",
    "def plot_confusion_matrix(cm, classes,\r\n",
    "                          normalize=False,\r\n",
    "                          title='Confusion matrix',\r\n",
    "                          cmap=plt.cm.Blues):\r\n",
    "    \"\"\"\r\n",
    "    This function prints and plots the confusion matrix.\r\n",
    "    Normalization can be applied by setting `normalize=True`.\r\n",
    "    \"\"\"\r\n",
    "    if normalize:\r\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
    "        print(\"Normalized confusion matrix\")\r\n",
    "    else:\r\n",
    "        print('Confusion matrix, without normalization')\r\n",
    "\r\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
    "    plt.title(title)\r\n",
    "    plt.colorbar()\r\n",
    "    tick_marks = np.arange(len(classes))\r\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
    "    plt.yticks(tick_marks, classes)\r\n",
    "\r\n",
    "    fmt = '.2f' if normalize else 'd'\r\n",
    "    thresh = cm.max() / 2.\r\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\r\n",
    "                 horizontalalignment=\"center\",\r\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
    "\r\n",
    "    plt.tight_layout()\r\n",
    "    plt.ylabel('True label')\r\n",
    "    plt.xlabel('Predicted label')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "names = [\r\n",
    "            # \"Nearest Neighbors\",\r\n",
    "            # \"SVM Linear\",\r\n",
    "            # \"SVM rbf\",\r\n",
    "            # \"GP\",\r\n",
    "            \"Decision Tree\"\r\n",
    "            # \"Random Forest\",\r\n",
    "            \"Neural Net\", \r\n",
    "            # \"AdaBoost\",\r\n",
    "            # \"Naive Bayes\",\r\n",
    "            # \"QDA\"\r\n",
    "        ]        \r\n",
    "        \r\n",
    "classifiers = [\r\n",
    "    # KNeighborsClassifier(500),\r\n",
    "    # SVC(kernel=\"linear\", C=0.03, probability = True),\r\n",
    "    # SVC(gamma=1.5, C=1, probability = True),\r\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\r\n",
    "    DecisionTreeClassifier(criterion='gini', max_depth=27, random_state=42),\r\n",
    "    # RandomForestClassifier(max_depth=200, n_estimators=400),\r\n",
    "    MLPClassifier(alpha=2),\r\n",
    "    # AdaBoostClassifier(),\r\n",
    "    # GaussianNB(),\r\n",
    "    # QuadraticDiscriminantAnalysis()\r\n",
    "    ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from sklearn import metrics\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "i=1\r\n",
    "plt.figure(figsize=(20,4))\r\n",
    "for name, clf in zip(names, classifiers):\r\n",
    "        ax = plt.subplot(1 , len(classifiers) + 1, i)\r\n",
    "        \r\n",
    "\r\n",
    "        start = time.time()\r\n",
    "        # fit the model using the training set\r\n",
    "        clf.fit(X_train, y_train)\r\n",
    "        end = time.time()\r\n",
    "        # compute the mean accuracy of the classifier\r\n",
    "        # score = clf.score(X_test, y_test)\r\n",
    "        end2 = time.time()\r\n",
    "        # compute ROC curve\r\n",
    "        # y_test_pred = clf.predict_proba(X_test)[:, 1]\r\n",
    "\r\n",
    "        y_pred=clf.predict(X_test)\r\n",
    "\r\n",
    "        # Classification results on test set\r\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\r\n",
    "        print(\"Accuracy: {:.2f}\".format(accuracy))\r\n",
    "\r\n",
    "        cm=confusion_matrix(y_test,y_pred)\r\n",
    "        print('Confusion Matrix: \\n', cm)\r\n",
    "        print(classification_report(y_test, y_pred, target_names=class_names))\r\n",
    "\r\n",
    "        # plt.subplots()\r\n",
    "        # plot_confusion_matrix(metrics.confusion_matrix(y_test, y_pred >= 0.5), range(2))\r\n",
    "        # plt.subplots()\r\n",
    "        # plot_confusion_matrix(metrics.confusion_matrix(y_test, y_pred >= 0.5), range(2), normalize=True, title='Normalized confusion matrix')\r\n",
    "        \r\n",
    "        print(name,str(end-start),str(end2 - end))\r\n",
    "\r\n",
    "        i += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # Visualize the tree by graphiz\r\n",
    "# import graphviz\r\n",
    "# from sklearn import tree\r\n",
    "# import os\r\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Users/matia/anaconda3/Library/bin/graphviz/'\r\n",
    "# feature_names = X_columns\r\n",
    "# dot_data = tree.export_graphviz(classifier, out_file=None, filled=True, rounded = True, feature_names=feature_names, class_names=class_names)\r\n",
    "# graph = graphviz.Source(dot_data)\r\n",
    "# graph"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# i=1\r\n",
    "# plt.figure(figsize=(20,4))\r\n",
    "# for name, clf in zip(names, classifiers):\r\n",
    "#         ax = plt.subplot(1 , len(classifiers) + 1, i)\r\n",
    "        \r\n",
    "\r\n",
    "#         start = time.time()\r\n",
    "#         # fit the model using the training set\r\n",
    "#         clf.fit(X_train, y_train)\r\n",
    "#         end = time.time()\r\n",
    "#         # compute the mean accuracy of the classifier\r\n",
    "#         score = clf.score(X_test, y_test)\r\n",
    "#         end2 = time.time()\r\n",
    "#         compute ROC curve\r\n",
    "#         y_test_pred = clf.predict_proba(X_test)[:, 1]\r\n",
    "#         fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_pred, pos_label=1)\r\n",
    "#         auc = metrics.roc_auc_score(y_test, y_test_pred, multi_class='ovo')\r\n",
    "#         acc = metrics.accuracy_score(y_test, y_test_pred >= 0.5, multi_class='ovo')\r\n",
    "#         f1 = metrics.f1_score(y_test, y_test_pred >= 0.5, multi_class='ovo')\r\n",
    "#         ax.set_xlim(-.05, 1.05)\r\n",
    "#         ax.set_ylim(-.05, 1.05)\r\n",
    "#         ax.set_xticks(())\r\n",
    "#         ax.set_yticks(())\r\n",
    "#         ax.text(0.95, 0.3, \"Acc: %.2f\" % acc, ha = 'right')\r\n",
    "#         ax.text(0.95, 0.2, \"F1-score: %.2f\" % f1, ha = 'right')\r\n",
    "#         ax.text(0.95, 0.1, \"AUC: %.2f\" % auc, ha = 'right')\r\n",
    "#         ax.plot(fpr, tpr, lw = 5)\r\n",
    "#         idx = np.argmin(np.abs(thresholds - 0.5))\r\n",
    "#         ax.scatter(fpr[idx], tpr[idx], marker = 'o', c = 'r')\r\n",
    "#         print(name,str(end-start),str(end2 - end))\r\n",
    "#         counter \r\n",
    "#         i += 1"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd482b7cd4264c5ef4566bc86a2ab8bd2bb23c50b3c7d4b1f3e5fd5095eeae80"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}